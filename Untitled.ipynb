{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import tensorflow as tf\n",
    "from  sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= 'train_nor_811.xlsx'\n",
    "df = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enjoyment</td>\n",
       "      <td>u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enjoyment</td>\n",
       "      <td>m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotion                                           Sentence\n",
       "0      Other              cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n",
       "1    Disgust  cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...\n",
       "2    Disgust  lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...\n",
       "3  Enjoyment    u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))\n",
       "4  Enjoyment  m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns={'Unnamed: 0'},axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                           Sentence\n",
       "0        4              cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n",
       "1        1  cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...\n",
       "2        1  lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...\n",
       "3        2    u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))\n",
       "4        2  m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encodeEmotion = encoder.fit_transform(df.Emotion)\n",
    "df.Emotion = encoder_label\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "for i in range(len(df)):\n",
    "    data.append(df.Sentence[i])\n",
    "    label.append(df.Emotion[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°\n",
      "cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ra m√† ƒë√°nh üò°\n",
      "lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc sinh h·ªçc\n",
      "[14, 24, 275, 211, 520, 483, 3, 18, 54, 246]\n",
      "[14, 117, 135, 11, 1011, 79, 48, 2158, 11, 48, 25, 26, 5, 267, 1183]\n",
      "[484, 84, 8, 34, 1012, 216, 18, 49, 21, 114, 84, 203, 84]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  14  24 275 211 520 483   3  18  54 246]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0   14\n",
      "  117  135   11 1011   79   48 2158   11   48   25   26    5  267 1183]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0  484   84    8   34 1012  216   18   49   21  114   84  203   84]\n",
      "(5548, 154)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(data)\n",
    "print(data[0])\n",
    "print(data[1])\n",
    "print(data[2])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data)\n",
    "print(X[0])\n",
    "print(X[1])\n",
    "print(X[2])\n",
    "X = pad_sequences(X)\n",
    "print(X[0])\n",
    "print(X[1])\n",
    "print(X[2])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (5548, 154)\n",
      "Vocab count 4420\n"
     ]
    }
   ],
   "source": [
    "print(\"input shape\",X.shape)\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "print('Vocab count',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 154)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 154, 128)     565760      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 154, 100)     12900       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 153, 100)     25700       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 77, 100)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 76, 100)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7700)         0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7600)         0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 15300)        0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 28)           428428      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 14)           406         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 7)            105         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,033,299\n",
      "Trainable params: 1,033,299\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "maxlen = X.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=( maxlen , ))\n",
    "embedding = layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inputs)\n",
    "\n",
    "cnn1=layers.Conv1D(filters=100, kernel_size=1, activation='relu')(embedding)\n",
    "cnn1 = layers.MaxPooling1D(pool_size=2)(cnn1)\n",
    "cnn1 = Flatten()(cnn1)\n",
    "\n",
    "cnn2=layers.Conv1D(filters=100, kernel_size=2, activation='relu')(embedding)\n",
    "cnn2 = layers.MaxPooling1D(pool_size=2)(cnn2)\n",
    "cnn2 = Flatten()(cnn2)\n",
    "\n",
    "outputs = layers.Concatenate()([cnn1,cnn2])\n",
    "\n",
    "outputs = layers.Dense(28, activation='tanh')(outputs)\n",
    "outputs = layers.Dense(14, activation='tanh')(outputs)\n",
    "outputs = layers.Dense(7, activation='softmax')(outputs)\n",
    "model=models.Model(inputs,outputs)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t√°ch train test\n",
    "Y = tf.keras.utils.to_categorical(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - 7s 29ms/step - loss: 0.4392 - accuracy: 0.2056 - val_loss: 0.3806 - val_accuracy: 0.3129\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 6s 29ms/step - loss: 0.3678 - accuracy: 0.3535 - val_loss: 0.3525 - val_accuracy: 0.3922\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 6s 29ms/step - loss: 0.3299 - accuracy: 0.4396 - val_loss: 0.3445 - val_accuracy: 0.3929\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 6s 29ms/step - loss: 0.2929 - accuracy: 0.5196 - val_loss: 0.3280 - val_accuracy: 0.4398\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 6s 29ms/step - loss: 0.2311 - accuracy: 0.7003 - val_loss: 0.3226 - val_accuracy: 0.4968\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 7s 32ms/step - loss: 0.1704 - accuracy: 0.8321 - val_loss: 0.3343 - val_accuracy: 0.4953\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 6s 30ms/step - loss: 0.1259 - accuracy: 0.8902 - val_loss: 0.3553 - val_accuracy: 0.4773\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 7s 32ms/step - loss: 0.0949 - accuracy: 0.9348 - val_loss: 0.3741 - val_accuracy: 0.4831\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 7s 32ms/step - loss: 0.0738 - accuracy: 0.9665 - val_loss: 0.3940 - val_accuracy: 0.4766\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 7s 32ms/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.4109 - val_accuracy: 0.4823\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9257\n",
      "Testing Accuracy:  0.4888\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 154, 128)          565760    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 855,591\n",
      "Trainable params: 855,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "hidden_size = 200\n",
    "batch_size = 32\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embed_dim, input_length = X.shape[1]))\n",
    "model.add(layers.LSTM(hidden_size))\n",
    "model.add(layers.Dense(128,activation = 'sigmoid'))\n",
    "model.add(layers.Dense(7,activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t√°ch train test\n",
    "Y = tf.keras.utils.to_categorical(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - 42s 193ms/step - loss: 1.8640 - accuracy: 0.2434 - val_loss: 1.7480 - val_accuracy: 0.3634\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 42s 203ms/step - loss: 1.6747 - accuracy: 0.3552 - val_loss: 1.5872 - val_accuracy: 0.4211\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 46s 220ms/step - loss: 1.4200 - accuracy: 0.4853 - val_loss: 1.5345 - val_accuracy: 0.4492\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 45s 215ms/step - loss: 1.1958 - accuracy: 0.5659 - val_loss: 1.5251 - val_accuracy: 0.4557\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 44s 210ms/step - loss: 1.0145 - accuracy: 0.6297 - val_loss: 1.5810 - val_accuracy: 0.4701\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 44s 211ms/step - loss: 0.8652 - accuracy: 0.7017 - val_loss: 1.6188 - val_accuracy: 0.4787\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 52s 250ms/step - loss: 0.7312 - accuracy: 0.7453 - val_loss: 1.7550 - val_accuracy: 0.4780\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 43s 208ms/step - loss: 0.6613 - accuracy: 0.7795 - val_loss: 1.7908 - val_accuracy: 0.4881\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 45s 213ms/step - loss: 0.5677 - accuracy: 0.8175 - val_loss: 1.8441 - val_accuracy: 0.4838\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 52s 247ms/step - loss: 0.4359 - accuracy: 0.8568 - val_loss: 1.9680 - val_accuracy: 0.4701\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
